<h2 align="center"> <a href="">Interpreting Multimodal Large Lanugage Models</a></h2>
<h5 align="center"> If you like our project, please give us a star â­ on GitHub for latest update.  </h2>

## ğŸ“° News & Update

- **[2025.05.03]** We begin by investigating the possibility of attribution in multimodal large language models (MLLMs).

## ğŸ› ï¸ Environment

For our interpretation method, the packages we use are relatively common. Please mainly install `pytorch`, etc.

## ğŸ§³ Quickly Try

You can experience the interpretability of a single image directly in the Jupyter notebook.

## ğŸ—ï¸ How to Run

Prepare the datasets following [here](datasets/README.md).

