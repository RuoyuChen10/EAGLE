# -- coding: utf-8 --**

"""
Created on 2024/10/06

@author: Ruoyu Chen
"""

import argparse

import os
import os
import json
import cv2
import numpy as np
from matplotlib import pyplot as plt
from PIL import Image

from tqdm import tqdm

from sklearn import metrics

def parse_args():
    parser = argparse.ArgumentParser(description='Faithfulness Metric')
    parser.add_argument('--explanation-dir', 
                        type=str, 
                        default='interpretation_results/LLaVA-1_5-7B-coco-object/slico-1.0-1.0-division-number-64',
                        help='Save path for saliency maps generated by our methods.')
    parser.add_argument('--sensitiveity', 
                        type=float, 
                        default=0.2,
                        help='')
    args = parser.parse_args()
    return args

def main(args):
    print(args.explanation_dir)
    
    json_root_file = os.path.join(args.explanation_dir, "json")
    json_file_names = os.listdir(json_root_file)
    
    insertion_aucs = []
    deletion_aucs = []
    
    highest_score = []
    highest_score_sensitiveity = []
    
    insertion_sensitiveity_aucs = []
    deletion_sensitiveity_aucs = []
    
    for json_file_name in tqdm(json_file_names):
        json_file_path = os.path.join(json_root_file, json_file_name)
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            saved_json_file = json.load(f)
            
        insertion_area = np.array([0] + saved_json_file["region_area"])
        deletion_area = 1 - insertion_area
        
        insertion_score = np.array([saved_json_file["deletion_score"][-1]] + saved_json_file["insertion_score"])
        
        deletion_score = np.array([saved_json_file["insertion_score"][-1]] + saved_json_file["deletion_score"])
        
        # sensitiveity word
        sensitiveity_index = (np.array(saved_json_file["insertion_word_score"][-1]) - np.array(saved_json_file["deletion_word_score"][-1])) > args.sensitiveity
        if sensitiveity_index.sum() >0:
            insertion_sensitiveity_auc_score = [
                np.array(saved_json_file["deletion_word_score"][-1])[sensitiveity_index].mean()
            ]
            deletion_sensitiveity_auc_score = [
                np.array(saved_json_file["insertion_word_score"][-1])[sensitiveity_index].mean()
            ]
        
            for insertion_word_score in saved_json_file["insertion_word_score"]:
                insertion_sensitiveity_auc_score.append(
                    np.array(insertion_word_score)[sensitiveity_index].mean()
                )
            insertion_sensitiveity_auc_score = np.array(insertion_sensitiveity_auc_score)
            for deletion_word_score in saved_json_file["deletion_word_score"]:
                deletion_sensitiveity_auc_score.append(
                    np.array(deletion_word_score)[sensitiveity_index].mean()
                )
            deletion_sensitiveity_auc_score = np.array(deletion_sensitiveity_auc_score)
        
        # Computing AUC
        insertion_auc = metrics.auc(insertion_area, insertion_score)
        deletion_auc = metrics.auc(deletion_area, deletion_score)
        
        insertion_aucs.append(insertion_auc)
        deletion_aucs.append(deletion_auc)
        
        if sensitiveity_index.sum() >0:
            insertion_sensitiveity_auc = metrics.auc(insertion_area, insertion_sensitiveity_auc_score)
            deletion_sensitiveity_auc = metrics.auc(deletion_area, deletion_sensitiveity_auc_score)

            insertion_sensitiveity_aucs.append(insertion_sensitiveity_auc)
            deletion_sensitiveity_aucs.append(deletion_sensitiveity_auc)
        
        # highest cls
        highest_score.append(
            insertion_score.max()
        )
        if sensitiveity_index.sum() >0:
            highest_score_sensitiveity.append(
                insertion_sensitiveity_auc_score.max()
            )
    
    insertion_auc_score = np.array(insertion_aucs).mean()
    deletion_auc_score = np.array(deletion_aucs).mean()
    
    insertion_sensitiveity_auc_score = np.array(insertion_sensitiveity_aucs).mean()
    deletion_sensitiveity_auc_score = np.array(deletion_sensitiveity_aucs).mean()
    
    average_highest_score = np.array(highest_score).mean()
    average_highest_score_sensitiveity = np.array(highest_score_sensitiveity).mean()
    # average_highest_cls_score_75 = np.array(highest_auc_score_75).mean()
    
    print("Insertion AUC Score: {:.4f}\nDeletion AUC Score: {:.4f}".format(insertion_auc_score, deletion_auc_score))
    print("Average highest confidence: {:.4f}".format(average_highest_score))

    print("Insertion Sensitiveity AUC Score: {:.4f}\nDeletion Sensitiveity AUC Score: {:.4f}".format(insertion_sensitiveity_auc_score, deletion_sensitiveity_auc_score))
    print("Sensitiveity Average highest confidence: {:.4f}".format(average_highest_score_sensitiveity))

    return

if __name__ == "__main__":
    args = parse_args()
    main(args)