# -- coding: utf-8 --**

"""
Created on 2024/10/06

@author: Ruoyu Chen
"""

import argparse

import os
import os
import json
import cv2
import numpy as np
from matplotlib import pyplot as plt
from PIL import Image

from tqdm import tqdm

from sklearn import metrics

def parse_args():
    parser = argparse.ArgumentParser(description='Correction-oriented Metrics')
    parser.add_argument('--explanation-dir', 
                        type=str, 
                        default='interpretation_results/LLaVA-1_5-7B-RePOPE/slico-1.0-1.0-division-number-64',
                        help='Save path for saliency maps generated by our methods.')
    args = parser.parse_args()
    return args

def main(args):
    print(args.explanation_dir)
    
    json_root_file = os.path.join(args.explanation_dir, "json")
    json_file_names = os.listdir(json_root_file)
    
    insertion_aucs = []
    deletion_aucs = []
    highest_score = []
    
    AMCR_samples = []   # Average Minimal Correction Region
    CSR_10_samples = [] # Correction Success Rate under Budget
    
    for json_file_name in tqdm(json_file_names):
        json_file_path = os.path.join(json_root_file, json_file_name)
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            saved_json_file = json.load(f)
            
        insertion_area = np.array([0] + saved_json_file["region_area"])
        deletion_area = 1 - insertion_area
        
        insertion_score = np.array([saved_json_file["deletion_score"][-1]] + saved_json_file["insertion_score"])
        
        deletion_score = np.array([saved_json_file["insertion_score"][-1]] + saved_json_file["deletion_score"])
        
        # Computing AUC
        insertion_auc = metrics.auc(insertion_area, insertion_score)
        deletion_auc = metrics.auc(deletion_area, deletion_score)
        
        insertion_aucs.append(insertion_auc)
        deletion_aucs.append(deletion_auc)
        
        # highest cls
        highest_score.append(
            insertion_score.max()
        )
        
        # Average Minimal Correction Region
        label = saved_json_file["label"]
        if label == "yes":
            for k in range(1, len(saved_json_file["revised_answering"])+1):
                if saved_json_file["revised_answering"][-k][:3] == "Yes":
                    amcr_ = 1 - insertion_area[-k]
                    AMCR_samples.append(amcr_)
                    if amcr_ <= 0.1:
                        CSR_10_samples.append(1)
                    else:
                        CSR_10_samples.append(0)
                    break
                if k == len(saved_json_file["revised_answering"]):
                    AMCR_samples.append(1)
        elif label == "no":
            for k in range(1, len(saved_json_file["revised_answering"])+1):
                if saved_json_file["revised_answering"][-k][:2] == "No":
                    amcr_ = 1 - insertion_area[-k]
                    AMCR_samples.append(amcr_)
                    if amcr_ <= 0.1:
                        CSR_10_samples.append(1)
                    else:
                        CSR_10_samples.append(0)
                    break
                if k == len(saved_json_file["revised_answering"]):
                    AMCR_samples.append(1)
    
    insertion_auc_score = np.array(insertion_aucs).mean()
    deletion_auc_score = np.array(deletion_aucs).mean()
    
    average_highest_score = np.array(highest_score).mean()

    AMCR = np.array(AMCR_samples).mean()
    CSR_10 = np.array(CSR_10_samples).mean()
    
    print("Insertion AUC Score: {:.4f}\nDeletion AUC Score: {:.4f}".format(insertion_auc_score, deletion_auc_score))
    print("Average highest confidence: {:.4f}".format(average_highest_score))

    print("Average Minimal Correction Region (AMCR): {:.4f}".format(AMCR))
    print("Correction Success Rate under Budget (CSR@10%): {:.2%}".format(CSR_10))

    return

if __name__ == "__main__":
    args = parse_args()
    main(args)