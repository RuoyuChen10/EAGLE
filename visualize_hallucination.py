import argparse

import os
import json
import numpy as np
import textwrap
import re

import matplotlib.pyplot as plt
import matplotlib.ticker as mtick

from tqdm import tqdm
from utils import *

def parse_args():
    parser = argparse.ArgumentParser(description='Faithfulness Metric')
    parser.add_argument('--explanation-dir', 
                        type=str, 
                        default='new_baseline_res/Qwen2.5-VL-7B-RePOPE/TAM',
                        help='Save path for saliency maps generated by our methods.')
    parser.add_argument('--Datasets',
                        type=str,
                        default='datasets/coco2014/val2014',
                        help='Datasets.')
    args = parser.parse_args()
    return args

def add_value_hallucination(S_set, json_file):
    single_mask = np.zeros_like(S_set[0])
    single_mask = single_mask.astype(np.float16)
    
    value_list_1 = np.array(json_file["smdl_score"])
    value_list_2 = np.array(
        [np.mean(1 - np.array(json_file["insertion_score"][-1]) + np.array(json_file["deletion_score"][-1]))] + json_file["smdl_score"][:-1]
    )
    
    value_list = value_list_1 - value_list_2
    
    values = []
    value = 0
    i = 0
    for smdl_single_mask, smdl_value in zip(S_set, value_list):
        value = value - abs(smdl_value)
        single_mask[smdl_single_mask==1] = value
        values.append(value)
        i+=1
    attribution_map = single_mask - single_mask.min()
    attribution_map = attribution_map / attribution_map.max()
    
    return 1 - attribution_map, np.array(values)

def gen_cam_hallucination(image_path, mask):
    """
    Generate heatmap
        :param image: [H,W,C]
        :param mask: [H,W],range 0-1
        :return: tuple(cam,heatmap)
    """
    # Read image
    w = mask.shape[1]
    h = mask.shape[0]
    image = cv2.resize(cv2.imread(image_path), (w,h))
    # mask->heatmap
    mask = cv2.resize(mask, (int(w/20),int(h/20)))
    mask = cv2.resize(mask, (w,h))
    heatmap = cv2.applyColorMap(np.uint8(mask), cv2.COLORMAP_COOL)  # cv2.COLORMAP_COOL
    heatmap = np.float32(heatmap)

    # merge heatmap to original image
    cam = 0.5*heatmap + 0.5*np.float32(image)
    return cam.astype(np.uint8), (heatmap).astype(np.uint8)

def norm_image(image):
    """
    Normalization image
    :param image: [H,W,C]
    :return:
    """
    image = image.copy()
    image -= np.max(np.min(image), 0)
    image /= np.max(image)
    image *= 255.
    return np.uint8(image)

def visualization_hallucination(image, S_set, saved_json_file, vis_image, index=None):
    S_set_add = S_set.copy()
    S_set_add = S_set_add[::-1]
    S_set_add = np.array([S_set_add[0]-S_set_add[0]] + S_set_add)
    image_baseline = cv2.resize(image, (S_set[0].shape[1], S_set[0].shape[0]))
    
    revised_answering = saved_json_file["revised_answering"][::-1]
    revised_answering.append("No answer")
    
    org_output = saved_json_file["revised_answering"][-1]

    deletion_ours_images = []

    insertion_image = (S_set_add[0] - S_set_add[0]) * image_baseline
    # insertion_ours_images.append(insertion_image)
    deletion_ours_images.append(image_baseline)
    for smdl_sub_mask in S_set_add:
        insertion_image = insertion_image.copy() + smdl_sub_mask * image_baseline
        # insertion_ours_images.append(insertion_image)
        deletion_ours_images.append(image_baseline - insertion_image)
        
    curve_score = [saved_json_file["deletion_score"][-1]] + saved_json_file["insertion_score"]
    curve_score = curve_score[::-1]

    ours_best_index = -1
    
    if index == None:
        # ours_best_index = np.argmax(curve_score)
        label = saved_json_file["label"]
        if label == "yes":
            for k in range(1, len(saved_json_file["revised_answering"])+1):
                if saved_json_file["revised_answering"][-k][:3] == "Yes":
                    ours_best_index = k - 1
                    break
        elif label == "no":
            for k in range(1, len(saved_json_file["revised_answering"])+1):
                if saved_json_file["revised_answering"][-k][:2] == "No":
                    ours_best_index = k - 1
                    break
    else:
        ours_best_index = index
        
    x = [0.0] + saved_json_file["region_area"]  # bug
    x = (1 - np.array(x)).tolist()[::-1]
    i = len(x)

    # fig, [ax1, ax2, ax3] = plt.subplots(1,3, gridspec_kw = {'width_ratios':[2, 2, 1.5]}, figsize=(30,8))
    # fig.subplots_adjust(wspace=0.4)  # 增加wspace值，增加图2和图3之间的间隔
    fig = plt.figure(figsize=(30, 8))
    
    ax1 = fig.add_axes([0.05, 0.1, 0.3, 0.8])  # 图1位置
    ax2 = fig.add_axes([0.37, 0.1, 0.3, 0.8])  # 图2位置
    ax3 = fig.add_axes([0.75, 0.1, 0.25, 0.8])
    
    ax1.spines["left"].set_visible(False)
    ax1.spines["right"].set_visible(False)
    ax1.spines["top"].set_visible(False)
    ax1.spines["bottom"].set_visible(False)
    ax1.xaxis.set_visible(True)
    ax1.yaxis.set_visible(False)
    ax1.set_title('Attribution Map', fontsize=54, pad=30)
    ax1.set_facecolor('white')
    
    hallucination_aws = r"$\bf{Hallucinated \ response:}$" + "\n" + "\n".join(textwrap.wrap(org_output, width=45))
    wrapped = "\n".join(textwrap.wrap(revised_answering[ours_best_index], width=45))
    final_label = hallucination_aws + "\n" + r"$\bf{Revised\ answer:}$" + "\n" + wrapped
    ax1.set_xlabel(final_label, fontsize=44, ha='left')
    ax1.xaxis.set_label_coords(0, -0.05)
    ax1.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)
    ax1.imshow(vis_image[...,::-1].astype(np.uint8))
    
    ax2.spines["left"].set_visible(False)
    ax2.spines["right"].set_visible(False)
    ax2.spines["top"].set_visible(False)
    ax2.spines["bottom"].set_visible(False)
    ax2.xaxis.set_visible(True)
    ax2.yaxis.set_visible(False)
    ax2.set_title('Hallucination Mitigation', fontsize=54, pad=30)
    ax2.set_facecolor('white')
    ax2.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)

    ax3.set_xlim((0, 1))
    ax3.set_ylim((0, 1))
    yticks = ax3.get_yticks()
    yticks = yticks[yticks != 0]
    ax3.set_yticks(yticks)
    
    ax3.set_ylabel('Corrected Score', fontsize=44)
    ax3.set_xlabel('Remove Biased Region', fontsize=44)

    ax3.tick_params(axis='both', which='major', labelsize=40)

    curve_color = "#FF4500"
    # curve_color = "#1E90FF"

    x_ = x[:i]
    ours_y = curve_score[:i]
    ax3.plot(x_, ours_y, color=curve_color, linewidth=3.5)  # draw curve
    ax3.set_facecolor('white')
    ax3.spines['bottom'].set_color('black')
    ax3.spines['bottom'].set_linewidth(2.0)
    ax3.spines['top'].set_color('none')
    ax3.spines['left'].set_color('black')
    ax3.spines['left'].set_linewidth(2.0)
    ax3.spines['right'].set_color('none')

    # plt.legend(["Ours"], fontsize=40, loc="upper left")
    ax3.scatter(x_[-1], ours_y[-1], color=curve_color, s=54)  # Plot latest point
    # 在曲线下方填充淡蓝色
    ax3.fill_between(x_, ours_y, color=curve_color, alpha=0.1)

    kernel = np.ones((10, 10), dtype=np.uint8)
    # ax3.plot([x_[ours_best_index], x_[ours_best_index]], [0, 1], color='red', linewidth=3.5)  # 绘制红色曲线
    ax3.axvline(x=x_[ours_best_index], color='red', linewidth=3.5)  # 绘制红色垂直线
    ax3.xaxis.set_major_formatter(mtick.PercentFormatter(xmax=1, decimals=0))

    mask = 1-(S_set_add.sum(0) - S_set_add[:ours_best_index+1].sum(0)).sum(-1).astype('uint8')

    if ours_best_index != 0:
        dilate = cv2.dilate(mask, kernel, 3)
        edge = dilate - mask

    image_debug = image_baseline.copy()
    image_debug[mask>0] = image_debug[mask>0] * 0.3
    if ours_best_index != 0:
        image_debug[edge>0] = np.array([0,0,255])
    
    image_debug = cv2.resize(image_debug, (image.shape[1],image.shape[0]))
    ax2.imshow(image_debug[...,::-1])
    
    # auc = metrics.auc(x, curve_score)
    ax3.set_title('Corrected Target Score', fontsize=54, pad=30)

def perturbed(mask, rate = 0.5):
    mask_flatten = mask.flatten()
    number = int(len(mask_flatten) * rate)
    
    new_mask = np.zeros_like(mask_flatten)
    index = np.argsort(-mask_flatten)
    new_mask[index[:number]] = 1
        
    new_mask = new_mask.reshape((mask.shape[0], mask.shape[1]))
    
    return new_mask

def main(args):
    print(args.explanation_dir)
    
    json_root_file = os.path.join(args.explanation_dir, "json")
    npy_root_file = os.path.join(args.explanation_dir, "npy")
    
    full_visualization_path = os.path.join(args.explanation_dir, "visualization")
    mkdir(full_visualization_path)
    
    json_file_names = os.listdir(json_root_file)
    for json_file_name in tqdm(json_file_names):
        json_file_path = os.path.join(json_root_file, json_file_name)
        npy_file_path = os.path.join(npy_root_file, json_file_name.replace(".json", ".npy"))
        
        image_path = os.path.join(args.Datasets, re.sub(r'_\d+(?=\.json$)', '', json_file_name).replace(".json", ".jpg"))
        
        save_full_visualization_map_path = os.path.join(full_visualization_path, json_file_name.replace(".json", ".png"))
        if os.path.exists(save_full_visualization_map_path):
            continue
        
        with open(json_file_path, 'r', encoding='utf-8') as f:
            saved_json_file = json.load(f)
        
        image = cv2.imread(image_path)
        
        if "interpretation_results" in npy_file_path:
            S_set = np.load(npy_file_path)
            
            attribution_map, _ = add_value_hallucination(S_set, saved_json_file)
            vis_saliency_map, heatmap = gen_cam_hallucination(image_path, norm_image(attribution_map[:,:,0]))
            
        else:
            attribution_map = 1 - np.load(npy_file_path)
            if "IGOS_PP" in npy_file_path:
                attribution_map = -attribution_map
            # elif "TAM" in npy_file_path:
            #     attribution_map = -attribution_map

            attribution_map = attribution_map - attribution_map.min()
            attribution_map = attribution_map / (attribution_map.max() + 0.00000001)
            attribution_map = cv2.resize(attribution_map, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_LINEAR)
            if "TAM" in npy_file_path:
                vis_saliency_map, heatmap = gen_cam_hallucination(image_path, norm_image(-attribution_map))
            else:
                vis_saliency_map, heatmap = gen_cam_hallucination(image_path, norm_image(attribution_map))
        
            S_set = []
            
            current_mask = np.zeros_like(attribution_map)
            for perturbed_rate in saved_json_file["region_area"]:
                new_mask = perturbed(attribution_map, perturbed_rate)
                S_set.append(new_mask - current_mask)
                current_mask = new_mask
            S_set = np.array(S_set)[..., None]
                
        visualization_hallucination(image, S_set, saved_json_file, vis_saliency_map)
        plt.savefig(save_full_visualization_map_path, bbox_inches='tight', pad_inches=0)
        
        plt.close()
        
if __name__ == "__main__":
    args = parse_args()
    main(args)